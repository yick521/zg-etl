package com.zhugeio.etl.pipeline.main;

import com.alibaba.fastjson2.JSONObject;
import com.zhugeio.etl.pipeline.entity.ZGMessage;
import com.zhugeio.etl.pipeline.kafka.ZGMsgSchema;
import com.zhugeio.etl.pipeline.operator.gate.*;
import com.zhugeio.etl.pipeline.operator.id.*;
import com.zhugeio.etl.pipeline.sink.CustomKafkaSink;
import com.zhugeio.tool.properties.PropertiesUtil;
import org.apache.flink.api.common.eventtime.WatermarkStrategy;
import org.apache.flink.connector.kafka.source.KafkaSource;
import org.apache.flink.connector.kafka.source.enumerator.initializer.OffsetsInitializer;
import org.apache.flink.contrib.streaming.state.EmbeddedRocksDBStateBackend;
import org.apache.flink.streaming.api.CheckpointingMode;
import org.apache.flink.streaming.api.datastream.*;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.util.OutputTag;
import org.apache.kafka.clients.consumer.OffsetResetStrategy;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Properties;
import java.util.concurrent.TimeUnit;


public class IdJob {
    private static final Logger logger = LoggerFactory.getLogger(IdJob.class);
    public static void main(String[] args) {
        Properties configProperties = PropertiesUtil.getProperties("config.properties");
        System.out.println("configProperties : "+configProperties);
        logger.info("configProperties : {}",configProperties);
        int asyncCapacity = Integer.parseInt(configProperties.getProperty("async.capacity"));
        String kvrocksHost = configProperties.getProperty("kvrocks.host");
        int kvrocksPort = Integer.parseInt(configProperties.getProperty("kvrocks.port"));
        int maxPropLength = Integer.parseInt(configProperties.getProperty("maxPropLength", "100"));

        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        initCheckpoint(env, configProperties);
        int parallelism = env.getParallelism();  // æäº¤ä»»åŠ¡çš„å‘½ä»¤ä¸­æŒ‡å®šçš„å…¨å±€å¹¶è¡Œåº¦
        logger.info("parallelism : {}",parallelism);

        // 1. åˆ›å»º KafkaSourceï¼Œä½¿ç”¨è‡ªå®šä¹‰ååºåˆ—åŒ–æ¨¡å¼è·å–åˆ†åŒºä¿¡æ¯
        KafkaSource<ZGMessage> kafkaSource = KafkaSource.<ZGMessage>builder()
                .setBootstrapServers(configProperties.getProperty("kafka.brokers"))
                .setTopics(configProperties.getProperty("kafka.id.sourceTopic"))
                .setGroupId(configProperties.getProperty("kafka.id.group.id"))
                .setStartingOffsets(OffsetsInitializer.committedOffsets(OffsetResetStrategy.EARLIEST)) // ä¼˜å…ˆç”¨å·²æäº¤åç§»é‡ï¼Œæ²¡æœ‰åˆ™ä»æœ€æ—©å¼€å§‹
                .setProperties(getRateLimitProperties(configProperties))
                .setDeserializer(new ZGMsgSchema())
                .build();

        // 2. åˆ›å»ºæ•°æ®æµ
        DataStream<ZGMessage> source = env.fromSource(
                kafkaSource,
                WatermarkStrategy.noWatermarks(),
                "Kafka-Source-id"
        );

        DataStream<ZGMessage> execute = IdJob.execute(source, configProperties, parallelism);
        CustomKafkaSink.addCustomKafkaSink(execute.map(ZGMessage::getRawData), configProperties.getProperty("kafka.dw.sourceTopic"),
                configProperties.getProperty("kafka.brokers"), true, "id-sink");
        try {
            env.execute("etl-pipLine-IdJob");
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }

    public static DataStream<ZGMessage> execute(DataStream<ZGMessage> source,Properties configProperties,int parallelism){
        int asyncCapacity = Integer.parseInt(configProperties.getProperty("async.capacity"));
        String kvrocksHost = configProperties.getProperty("kvrocks.host");
        int kvrocksPort = Integer.parseInt(configProperties.getProperty("kvrocks.port"));
        int maxPropLength = Integer.parseInt(configProperties.getProperty("maxPropLength", "100"));
        // id : 0. å¤„ç†å¹¿å‘Š åˆå§‹åŒ– æ‰¹æ¬¡å¤„ç†å‰æ›´æ–°éƒ¨åˆ†å¿…é¡»çš„ç¼“å­˜æ•°æ® ä¼šå½±å“idæ¨¡å—æ¶ˆè´¹é€Ÿåº¦
        DataStream<ZGMessage> idStep0;
        String advBussStart = configProperties.getProperty("adv.buss.start");
        if("true".equals(advBussStart)){
            idStep0 = AsyncDataStream.unorderedWait(
                            source,
                            new AdvAsyncOperator(
                                    configProperties.getProperty("adv.redis.host"),
                                    Integer.parseInt(configProperties.getProperty("adv.redis.port")),
                                    Boolean.parseBoolean(configProperties.getProperty("adv.redis.isCluster"))
                            ),
                            Integer.parseInt(configProperties.getProperty("async.timeout.ms")),
                            TimeUnit.MILLISECONDS,
                            Integer.parseInt(configProperties.getProperty("async.thread.num"))
                    ).name("id-advAsyncIO")
                    .uid("id-advAsyncIO")
                    .setParallelism(parallelism);
        }else {
            idStep0 = source;
        }

        // id : 1.æ£€æŸ¥æ˜¯å¦æ˜¯jsonæ ¼å¼æ•°æ®
        DataStream<ZGMessage> idStep1 = idStep0.map(new CheckJsonAndOwnerOperator());

        // id : 2.appId business è®¾ç½®
        SingleOutputStreamOperator<ZGMessage> idStep2 = AsyncDataStream.unorderedWait(
                        idStep1,
                        new SetAppIdAndBusinessOperator(kvrocksHost, kvrocksPort, true, configProperties),
                        5000, TimeUnit.MILLISECONDS, asyncCapacity
                ).name("id-appId-AsyncIO")
                .uid("id-appId-AsyncIO")
                .setParallelism(parallelism);

        // id : 3.ç»Ÿä¸€Idå¤„ç†[è®¾å¤‡Id ä¼šè¯Id ç”¨æˆ·Id è¯¸è‘›Id]
        DataStream<ZGMessage> idStep3 = IdJob.processWithIdAndAsyncIO(idStep2, asyncCapacity, kvrocksHost, kvrocksPort,parallelism);


        // id : 4. å¤„ç†å¹¿å‘Š
        DataStream<ZGMessage> idStep4;
        if("true".equals(advBussStart)){
            // id : 4.1 å¤„ç†å¹¿å‘Š æŠ•æ”¾å››æœŸï¼šappç«¯å¹¿å‘Šä¿¡æ¯å­˜ssdb ip+ua
            SingleOutputStreamOperator<ZGMessage> advSaveAppAdDataStream;
            SingleOutputStreamOperator<ZGMessage> advSaveAppAdDataStream0 = idStep3.flatMap(
                            new AdvSaveAppAdDataFlatMapFunction(configProperties)
                    ).name("advSaveAppAdDataStream")
                    .uid("advSaveAppAdDataStream")
                    .setParallelism(parallelism);
            // åˆ†æµ é˜²æ­¢ è¢«å¤šæ¬¡éå†
            final OutputTag<String> advSaveAppAdDataTag = new OutputTag<String>("id-advSaveAppAdDataTag"){};
            // ä¸»æ•°æ®æµ
            advSaveAppAdDataStream = advSaveAppAdDataStream0.process(new AdvSaveAppAdDataProcessFunction(advSaveAppAdDataTag));
            // ä¾§è¾“å‡º - å¹¿å‘Šæ•°æ®
            SideOutputDataStream<String> advSaveAppAdDataSideOutput = advSaveAppAdDataStream.getSideOutput(advSaveAppAdDataTag);
            CustomKafkaSink.addCustomKafkaSink(advSaveAppAdDataSideOutput, configProperties.getProperty("kafka.adv.sinkTopic"),
                    configProperties.getProperty("kafka.brokers"), true, "id-advSaveAppAdDataSideOutput-sink");

            // id : 4.2 å¤„ç†å¹¿å‘Š æŠ•æ”¾äº”æœŸï¼šæ–°å¢ äº‹ä»¶å±æ€§ï¼ˆlidï¼‰ã€ç”¨æˆ·å±æ€§(é¦–æ¬¡ã€æœ«æ¬¡)
            SingleOutputStreamOperator<ZGMessage> advLidAndUserFirstEndDataStream;
            SingleOutputStreamOperator<ZGMessage> advLidAndUserFirstEndDataStream0 = advSaveAppAdDataStream0.flatMap(
                            new AdvLidAndUserFirstEndFlatMapFunction(configProperties)
                    ).name("id-advLidAndUserFirstEndDataStream0")
                    .uid("id-advLidAndUserFirstEndDataStream0")
                    .setParallelism(parallelism);
            // åˆ†æµ é˜²æ­¢ è¢«å¤šæ¬¡éå†
            final OutputTag<String> advLidAndUserFirstEndTag = new OutputTag<String>("advLidAndUserFirstEndTag"){};
            // ä¸»æ•°æ®æµ
            advLidAndUserFirstEndDataStream = advLidAndUserFirstEndDataStream0.process(new AdvLidAndUserFirstEndProcessFunction(advLidAndUserFirstEndTag));
            // ä¾§è¾“å‡º - å¹¿å‘Šæ•°æ®
            SideOutputDataStream<String> advLidAndUserFirstEndSideOutput = advLidAndUserFirstEndDataStream.getSideOutput(advLidAndUserFirstEndTag);
            CustomKafkaSink.addCustomKafkaSink(advLidAndUserFirstEndSideOutput, configProperties.getProperty("kafka.adv.sinkTopic"),
                    configProperties.getProperty("kafka.brokers"), true, "id-advLidAndUserFirstEndSideOutput-sink");
            idStep4 = advLidAndUserFirstEndDataStream;
        }else {
            idStep4 = idStep3;
        }


        // id : 5.è®¾å¤‡å±æ€§å¤„ç†
        SingleOutputStreamOperator<ZGMessage> idStep5 = AsyncDataStream.unorderedWait(
                        idStep4,
                        new DevicePropertyOperator(kvrocksHost, kvrocksPort, true),
                        5000, TimeUnit.MILLISECONDS, asyncCapacity
                ).name("devicePropProcess-AsyncIO")
                .uid("deviceProp-AsyncIO")
                .setParallelism(parallelism);

        // id : 6.è™šæ‹Ÿå±æ€§å¤„ç†
        SingleOutputStreamOperator<ZGMessage> idStep6 = AsyncDataStream.unorderedWait(
                        idStep5,
                        new VirtualPropertyOperator(kvrocksHost, kvrocksPort, true),
                        5000, TimeUnit.MILLISECONDS, asyncCapacity
                ).name("virtualPropProcess-AsyncIO")
                .uid("virtualProp-AsyncIO")
                .setParallelism(parallelism);

        // id : 7.è™šæ‹Ÿäº‹ä»¶å¤„ç†
        SingleOutputStreamOperator<ZGMessage> idStep7 = AsyncDataStream.unorderedWait(
                        idStep6,
                        new VirtualEventOperator(kvrocksHost, kvrocksPort, true),
                        5000, TimeUnit.MILLISECONDS, asyncCapacity
                ).name("virtualEventProcess-AsyncIO")
                .uid("virtualEvent-AsyncIO")
                .setParallelism(parallelism);

        // 8.ç”¨æˆ·å±æ€§å¤„ç†
        SingleOutputStreamOperator<ZGMessage> idStep8 = AsyncDataStream.unorderedWait(
                        idStep7,
                        new UserPropAsyncOperator(kvrocksHost, kvrocksPort, true, configProperties, maxPropLength),
                        5000, TimeUnit.MILLISECONDS, asyncCapacity
                ).name("userPropProcess-AsyncIO")
                .uid("userProp-AsyncIO")
                .setParallelism(parallelism);

        // 9.äº‹ä»¶å±æ€§å¤„ç†

        // id : 10 å¤„ç†å¹¿å‘Š
        SingleOutputStreamOperator<ZGMessage> idStep10;
        if("true".equals(advBussStart)){
            // id : 10.1 å¤„ç†å¹¿å‘Š æŠ•æ”¾äº”æœŸï¼šæŸ¥è¯¢å›ä¼ è¡¨åˆ¤æ–­æ˜¯å¦ç¬¦åˆå›ä¼ è¡Œä¸º (åŒ¹é…æ·±åº¦å›ä¼ äº‹ä»¶å¹¶å‘kafka)
            SingleOutputStreamOperator<ZGMessage> advConvertEventDataStream0 = idStep8.flatMap(
                            new AdvConvertEventFlatMapFunction(configProperties)
                    ).name("advConvertEventDataStream0")
                    .uid("advConvertEventDataStream0")
                    .setParallelism(parallelism);
            // åˆ†æµ é˜²æ­¢ è¢«å¤šæ¬¡éå†
            final OutputTag<String> advConvertEventTag = new OutputTag<String>("id-advConvertEventTag"){};
            final OutputTag<String> advConvertEventUserTag = new OutputTag<String>("id-advConvertEventUserTag"){};
            // ä¸»æ•°æ®
            SingleOutputStreamOperator<ZGMessage> advConvertEventDataStream = advConvertEventDataStream0.process(new AdvConvertEventProcessFunction(advConvertEventTag, advConvertEventUserTag));
            // ä¾§è¾“å‡º - å¹¿å‘Šæ•°æ®
            SideOutputDataStream<String> advConvertEventSideOutput = advConvertEventDataStream.getSideOutput(advConvertEventTag);
            CustomKafkaSink.addCustomKafkaSink(
                    advConvertEventSideOutput,
                    configProperties.getProperty("kafka.adv.sinkTopic"),
                    configProperties.getProperty("kafka.brokers"),
                    true,
                    "id-advConvertEventSideOutput-sink"
            );
            // ä¾§è¾“å‡º - å¹¿å‘Šæ•°æ® - ç”¨æˆ·
            SideOutputDataStream<String> advConvertEventUserSideOutput = advConvertEventDataStream.getSideOutput(advConvertEventUserTag);
            CustomKafkaSink.addCustomKafkaSink(
                    advConvertEventUserSideOutput,
                    configProperties.getProperty("kafka.adv.user.sinkTopic"),
                    configProperties.getProperty("kafka.brokers"),
                    true,
                    "id-advConvertEventUserSideOutput-sink"
            );
            idStep10 = advConvertEventDataStream;
        }else {
            idStep10 = idStep8;
        }

        // 11.è¾“å‡ºä¸»æ•°æ®æµå’Œæ•°æ®è´¨é‡
        // 11.1 æ•°æ®è´¨é‡åˆ†æµ
        final OutputTag<String> dataQualityTag4id = new OutputTag<String>("dataQualityTag4id"){};
        SingleOutputStreamOperator<ZGMessage> idResultStream = idStep10.process(new IdResultProcessFunction(dataQualityTag4id));
        SideOutputDataStream<String> idResultStreamSideOutput = idResultStream.getSideOutput(dataQualityTag4id);
        CustomKafkaSink.addCustomKafkaSink(idResultStreamSideOutput, configProperties.getProperty("kafka.quality.topic"),
                configProperties.getProperty("kafka.brokers"), true, "id-data-quality-sink");
        // 11.2 ä¸»æ•°æ®è¿”å›
        return idResultStream;
    }

    public static DataStream<ZGMessage> processWithIdAndAsyncIO(
            DataStream<ZGMessage> source,
            int capacity,
            String kvrocksHost,
            int kvrocksPort,
            int parallelism
            ) {

        System.out.println("ğŸ“Š ä½¿ç”¨æµå¼å¼‚æ­¥å¤„ç†ï¼ˆAsyncIO + çœŸå®KVRocksï¼‰\n");

        // 1. è®¾å¤‡IDæ˜ å°„
        SingleOutputStreamOperator<ZGMessage> withDeviceId = AsyncDataStream.unorderedWait(
                        source,
                        new DeviceIdAsyncOperator(kvrocksHost, kvrocksPort, true),
                        5000, TimeUnit.MILLISECONDS, capacity
                ).name("DeviceId-AsyncIO")
                .uid("device-id-async")
                .setParallelism(parallelism);

        // 2. ä¼šè¯IDå¤„ç†
        DataStream<ZGMessage> withSessionId = withDeviceId
                .process(new SessionIdProcessOperator())
                .name("SessionId-Process")
                .uid("session-id-process")
                .setParallelism(parallelism);

        // 3. ç”¨æˆ·IDæ˜ å°„
        SingleOutputStreamOperator<ZGMessage> withUserId = AsyncDataStream.unorderedWait(
                        withSessionId,
                        new UserIdAsyncOperator(kvrocksHost, kvrocksPort),
                        5000, TimeUnit.MILLISECONDS, capacity
                ).name("UserId-AsyncIO")
                .uid("user-id-async")
                .setParallelism(parallelism);

        // 4. è¯¸è‘›IDæ˜ å°„
        SingleOutputStreamOperator<ZGMessage> withZgid = AsyncDataStream.unorderedWait(
                        withUserId,
                        new ZgidAsyncOperator(kvrocksHost, kvrocksPort),
                        5000, TimeUnit.MILLISECONDS, capacity
                ).name("Zgid-AsyncIO")
                .uid("zgid-async")
                .setParallelism(parallelism);

        return withZgid;
    }

    /**
     * ä¸“é—¨è®¾ç½®é€Ÿç‡é™åˆ¶å±æ€§çš„æ–¹æ³•
     */
    private static Properties getRateLimitProperties(Properties configProperties) {
        Properties props = new Properties();
        // æ¯ä¸ªåˆ†åŒºfetchæœ€å¤§å­—èŠ‚
        props.setProperty("max.partition.fetch.bytes", configProperties.getProperty("kafka.max.partition.fetch.bytes"));
        // æ¯æ¬¡pollæœ€å¤§è®°å½•æ•°
        props.setProperty("max.poll.records", configProperties.getProperty("kafka.max.partition.fetch.bytes"));
        // æœåŠ¡å™¨ç­‰å¾…æ—¶é—´
        props.setProperty("fetch.max.wait.ms", configProperties.getProperty("kafka.fetch.max.wait.ms"));
        return props;
    }

    public static void initCheckpoint(StreamExecutionEnvironment env, Properties properties){
        env.enableCheckpointing(30 * 1000L);
        env.getCheckpointConfig().setCheckpointInterval(30 * 1000L);
        env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);
        env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);
        env.getCheckpointConfig().setTolerableCheckpointFailureNumber(5);
        EmbeddedRocksDBStateBackend stateBackend = new EmbeddedRocksDBStateBackend(true);
        stateBackend.setDbStoragePath("hdfs:///user/flink/checkpoints/"+properties.getProperty("checkpoint.id.path"));
        env.setStateBackend(stateBackend);
    }
}